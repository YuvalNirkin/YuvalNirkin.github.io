---
layout: post
title: "FSGAN: Subject Agnostic Face Swapping and Reenactment"
date: 2019-08-16 12:00:00 +0200
description: # Add post description (optional)
img: publications/fsgan/fsgan_teaser.jpg # Add image post (optional)
img_thumb: publications/fsgan/fsgan_teaser_thumb.jpg
post_desc: We present Face Swapping GAN (FSGAN) for face swapping and reenactment. Unlike previous work, FSGAN is subject agnostic and can be applied to pairs of faces without requiring training on those faces. To this end, we describe a number of technical contributions. We derive a novel recurrent neural network (RNN)--based approach for face reenactment which adjusts for both pose and expression variations and can be applied to a single image or a video sequence. For video sequences, we introduce continuous interpolation of the face views based on reenactment, Delaunay Triangulation, and barycentric coordinates. Occluded face regions are handled by a face completion network. Finally, we use a face blending network for seamless blending of the two faces while preserving target skin color and lighting conditions. This network uses a novel Poisson blending loss which combines Poisson optimization with perceptual loss. We compare our approach to existing state-of-the-art systems and show our results to be both qualitatively and quantitatively superior.
tags: [Face Swapping, Face Reenactment, Face Segmentation] # add tag
type: publication
---

[comment]: **Yuval Nirkin, Yosi Keller, and Tal Hassner, FSGAN: Subject Agnostic Face Swapping and Reenactment, IEEE International Conference on Computer Vision (ICCV)**
<center><h2><a href="http://iccv2019.thecvf.com/">ICCV 2019</a></h2></center>
<center><h3>
<a href="http://nirkin.com/">Yuval Nirkin</a> &nbsp;
<a href="http://yosi-keller.narod.ru/">Yosi Keller</a> &nbsp;
<a href="https://talhassner.github.io/home/">Tal Hassner</a>
</h3></center>

>We present Face Swapping GAN (FSGAN) for face swapping and reenactment. Unlike previous work, FSGAN is subject agnostic and can be applied to pairs of faces without requiring training on those faces. To this end, we describe a number of technical contributions. We derive a novel recurrent neural network (RNN)--based approach for face reenactment which adjusts for both pose and expression variations and can be applied to a single image or a video sequence. For video sequences, we introduce continuous interpolation of the face views based on reenactment, Delaunay Triangulation, and barycentric coordinates. Occluded face regions are handled by a face completion network. Finally, we use a face blending network for seamless blending of the two faces while preserving target skin color and lighting conditions. This network uses a novel Poisson blending loss which combines Poisson optimization with perceptual loss. We compare our approach to existing state-of-the-art systems and show our results to be both qualitatively and quantitatively superior.

## Overview
![Method Overview]({{site.baseurl}}/assets/img/publications/fsgan/system.jpg)

## Downloads
<table class="download" cellspacing="10" style = "text-align:center; margin-left: auto; margin-right: auto;" border="0">
<tr>
	<td><a href="https://arxiv.org/pdf/1908.05932.pdf"><img style = "height:110px;" src="{{site.baseurl}}/assets/img/publications/fsgan/thumb_paper.jpg" border="1"></a></td>
	<td><a href="http://github.com/{{site.github}}"><i class="fa fa-github" style="font-size:96px;color:black"></i></a></td>
</tr>
<tr>
	<td><a href="https://arxiv.org/pdf/1908.05932.pdf">Paper</a></td>
	<td><a href="http://github.com/{{site.github}}">Code (impending)</a></td>
</tr>
</table>

## Video
<center><div class="embed-container">
  <iframe
      src="https://www.youtube.com/embed/BsITEVX6hkE"
      width="960"
      height="540"
      frameborder="0"
      allowfullscreen="">
  </iframe>
</div></center>

## Citation
{% highlight html %}
{% raw %}
@inproceedings{nirkin2019_fsgan,
  title={{FSGAN}: Subject Agnostic Face Swapping and Reenactment},
  booktitle = {ICCV},
  author={Nirkin, Yuval and Keller, Yosi and Hassner, Tal},
  year={2019},
}
{% endraw %}
{% endhighlight %}
